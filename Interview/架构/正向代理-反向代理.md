## [正向代理和反向代理](https://www.jscape.com/blog/bid/87783/forward-proxy-vs-reverse-proxy)
### The Forward Proxy
![Forward](https://www.jscape.com/hs-fs/hub/26878/file-13610973-png/images/forward_proxy-3.png?width=1200&height=658&name=forward_proxy-3.png)

正向代理通常与防火墙一起使用，通过控制来自内部网络的客户端(定向到Internet上的主机)的流量来增强内部网络的安全性。因此，从安全的角度来看，正向代理主要是为了加强内部网络中的客户端计算机的安全性。

### The Reverse Proxy
![Reverse](https://www.jscape.com/hs-fs/hub/26878/file-13614809-png/images/reverse_proxy-resized-600.png)

In most cases, reverse proxy servers also act as load balancers for the servers behind it. Load balancers play a crucial role in providing high availability to network services that receive large volumes of requests. When a reverse proxy performs load balancing, it distributes incoming requests to a cluster of servers, all providing the same kind of service. So, for instance, a reverse proxy load balancing FTP services will have a cluster of FTP servers behind it. 

大多数情况，反向代理起到了负载均衡的作用。

### 反向代理和负载均衡(SLB - Server Load Balancer)
反向代理是实现负载均衡的一种方法先谈反向代理。

先谈反向代理。用户在请求时，先把请求发送给代理的服务器，然后由代理服务器根据算法去请求真实的服务器，最后返回给用户。这种做法，其一是提高了安全性；其二是通过多台的real server分担了用户的请求，实现了负载均衡。

再谈负载均衡。负载均衡的出现，是通过横向的扩展，尽可能地降低单台服务器的压力。常见WEB层面的负载均衡的方案有硬件F5、Nginx代理、LVS、各个云商的负载均衡服务(如AWS的ELB服务)等。负载均衡后面连的一般是实际提供服务的服务器，如通过ELB服务，可以做到流量的均匀分担，从而减少单机服务器的压力。

由于增加了负载均衡这层，所以单纯地使用某个方案还是要考虑单点的问题。负责由于负载均衡这个服务器未能承受住压力，宕机了，服务也是不可用的。所以Nginx、LVS尽量配置多台代理，可以故障转移和故障报警，从而及时去处理代理层服务器的问题。

#### 负载均衡方案有几种？
目前市面上最常见的负载均衡技术方案主要有三种：

- 基于DNS负载均衡

- 基于硬件负载均衡

- 基于软件负载均衡

三种方案各有优劣，DNS负载均衡可以实现在地域上的流量均衡，硬件负载均衡主要用于大型服务器集群中的负载需求，而软件负载均衡大多是基于机器层面的流量均衡。在实际场景中，这三种是可以组合在一起使用

1. 基于DNS负载均衡: 基于DNS来做负载均衡其实是一种最简单的实现方案，通过在DNS服务器上做一个简单配置即可。其原理就是当用户访问域名的时候，会先向DNS服务器去解析域名对应的IP地址，这个时候我们可以让DNS服务器根据不同地理位置的用户返回不同的IP。比如南方的用户就返回我们在广州业务服务器的IP，北方的用户来访问的话，我就返回北京业务服务器所在的IP。
在这个模式下，用户就相当于实现了按照「就近原则」将请求分流了，既减轻了单个集群的负载压力，也提升了用户的访问速度。
使用DNS做负载均衡的方案，天然的优势就是配置简单，实现成本非常低，无需额外的开发和维护工作。
但是也有一个明显的缺点是：当配置修改后，生效不及时。这个是由于DNS的特性导致的，DNS一般会有多级缓存，所以当我们修改了DNS配置之后，由于缓存的原因，会导致IP变更不及时，从而影响负载均衡的效果。
另外，使用DNS做负载均衡的话，大多是基于地域或者干脆直接做IP轮询，没有更高级的路由策略，所以这也是DNS方案的局限所在。

2. 基于硬件负载均衡: 硬件的负载均衡那就比较牛逼了，比如大名鼎鼎的 F5 Network Big-IP，也就是我们常说的 F5，它是一个网络设备，你可以简单的理解成类似于网络交换机的东西，完全通过硬件来抗压力，性能是非常的好，每秒能处理的请求数达到百万级，即 几百万/秒 的负载，当然价格也就非常非常贵了，十几万到上百万人民币都有。因为这类设备一般用在大型互联网公司的流量入口最前端，以及政府、国企等不缺钱企业会去使用。一般的中小公司是不舍得用的。

3. 基于软件负载均衡: 软件负载均衡是指使用软件的方式来分发和均衡流量。软件负载均衡，分为7层协议 和 4层协议。网络协议有七层，基于第四层传输层来做流量分发的方案称为4层负载均衡，例如 [LVS-Linux Virtual Server](https://blog.csdn.net/weixin_40470303/article/details/80541639)，而基于第七层应用层来做流量分发的称为7层负载均衡，例如 Nginx。这两种在性能和灵活性上是有些区别的。基于4层的负载均衡性能要高一些，一般能达到 几十万/秒 的处理量，而基于7层的负载均衡处理量一般只在 几万/秒 。基于软件的负载均衡的特点也很明显，便宜。在正常的服务器上部署即可，无需额外采购，就是投入一点技术去优化优化即可，因此这种方式是互联网公司中用得最多的一种方式。


#### 常用的均衡算法有哪些？
NO.1—— Random 随机
这是最简单的一种，使用随机数来决定转发到哪台机器上。

优点：简单使用，不需要额外的配置和算法。
缺点：随机数的特点是在数据量大到一定量时才能保证均衡，所以如果请求量有限的话，可能会达不到均衡负载的要求。


NO.2—— Round Robin 轮询
这个也很简单，请求到达后，依次转发，不偏不向。每个服务器的请求数量很平均。

缺点：当集群中服务器硬件配置不同、性能差别大时，无法区别对待。引出下面的算法。


NO.3—— Weighted Round Robin 加权轮询
这种算法的出现就是为了解决简单轮询策略中的不足。在实际项目中，经常会遇到这样的情况。

比如有5台机器，两台新买入的性能等各方面都特别好，剩下三台老古董。这时候我们设置一个权重，让新机器接收更多的请求。物尽其用、能者多劳嘛！


NO.4—— Least Connections 最少连接
这是最符合负载均衡算法的一个。需要记录每个应用服务器正在处理的连接数，然后将新来的请求转发到最少的那台上。


NO.5—— Source Hashing 源地址散列
根据请求的来源ip进行hash计算，然后对应到一个服务器上。之后所有来自这个ip的请求都由同一台服务器处理。
